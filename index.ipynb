{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading 'facebook_dataset.cvs', I noticed that the fields are delimited by using ','. So I parsed line by line through the dataset, separated the values and putting them in an array.\n",
    "\n",
    "The task states that 'Category', 'Address', 'Phone' and 'Company name' are the fields that are the most important for the new dataset. In the given datasets, the columns that contain that kind of information are 'categories', 'name', 'phone' and 'address'.\n",
    "\n",
    "I used a pandas dataframe because it is easier to access data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_column = []\n",
    "phone_column = []\n",
    "company_name_column = []\n",
    "address_column = []\n",
    "\n",
    "with open('facebook_dataset.csv', mode='r', encoding='utf-8') as file:\n",
    "    file = csv.reader(file, delimiter=',', quotechar='\"')\n",
    "    for row in file:\n",
    "        if len(row) > 15:\n",
    "            address_column.append(row[1])\n",
    "            category_column.append(row[2])\n",
    "            company_name_column.append(row[9])\n",
    "            phone_column.append(row[11])\n",
    "        else:\n",
    "            address_column.append(\"\") \n",
    "            category_column.append(\"\")  \n",
    "            company_name_column.append(\"\") \n",
    "            phone_column.append(\"\") \n",
    "\n",
    "\n",
    "#delete the first element in each array element because it containes the name of the column           \n",
    "phone_column.pop(0) \n",
    "category_column.pop(0) \n",
    "address_column.pop(0) \n",
    "company_name_column.pop(0) \n",
    "\n",
    "#test code\n",
    "#print(category_column)\n",
    "print(len(category_column))\n",
    "#print(phone_column)\n",
    "print(len(phone_column))\n",
    "#print(phone_column)\n",
    "print(len(company_name_column))\n",
    "#print(company_name_column)\n",
    "print(len(address_column))\n",
    "#print(address_column)\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Category': category_column,\n",
    "    'Address': address_column,\n",
    "    'Phone': phone_column,\n",
    "    'Company Name': company_name_column\n",
    "}\n",
    "\n",
    "df_facebook = pd.DataFrame(data)\n",
    "#print(df_facebook)\n",
    "\n",
    "#output in a file for easier reading\n",
    "output_file = 'output_data.csv'  \n",
    "df_facebook.to_csv(output_file, index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for 'google_dataset.cvs', it has the same delimiter, so I parsed the same way as the previous dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_column = []\n",
    "phone_column = []\n",
    "company_name_column = []\n",
    "address_column = []\n",
    "\n",
    "with open('google_dataset.csv', mode='r', encoding='utf-8') as file:\n",
    "    file = csv.reader(file, delimiter=',', quotechar='\"')\n",
    "    for row in file:\n",
    "        if len(row) > 13:\n",
    "            address_column.append(row[0])\n",
    "            category_column.append(row[1])\n",
    "            company_name_column.append(row[5])\n",
    "            phone_column.append(row[6])\n",
    "        else:\n",
    "            address_column.append(\"\") \n",
    "            category_column.append(\"\")  \n",
    "            company_name_column.append(\"\") \n",
    "            phone_column.append(\"\")\n",
    "\n",
    "\n",
    "#delete the first element in each array element because it containes the name of the column           \n",
    "phone_column.pop(0) \n",
    "category_column.pop(0) \n",
    "address_column.pop(0) \n",
    "company_name_column.pop(0) \n",
    "\n",
    "#test code\n",
    "#print(category_column)\n",
    "print(len(category_column))\n",
    "#print(phone_column)\n",
    "print(len(phone_column))\n",
    "#print(phone_column)\n",
    "print(len(company_name_column))\n",
    "#print(company_name_column)\n",
    "print(len(address_column))\n",
    "#print(address_column)\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Category': category_column,\n",
    "    'Address': address_column,\n",
    "    'Phone': phone_column,\n",
    "    'Company Name': company_name_column\n",
    "}\n",
    "\n",
    "df_google = pd.DataFrame(data)\n",
    "#print(df_google)\n",
    "\n",
    "output_file = 'output_data_google.csv'  \n",
    "df_google.to_csv(output_file, index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for 'website_dataset.cvs', the delimiter is ';'. The separating by fields is the same, only changing the delimiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_column = []\n",
    "phone_column = []\n",
    "company_name_column = []\n",
    "address_column = []\n",
    "\n",
    "with open('website_dataset.csv', mode='r', encoding='utf-8') as file:\n",
    "    file = csv.reader(file, delimiter=';', quotechar='\"')\n",
    "    for row in file:\n",
    "        if len(row) > 10:\n",
    "            address_column.append(row[0])\n",
    "            company_name_column.append(row[3])\n",
    "            phone_column.append(row[7])\n",
    "            category_column.append(row[10])\n",
    "        else:\n",
    "            address_column.append(\"\") \n",
    "            company_name_column.append(\"\")\n",
    "            phone_column.append(\"\") \n",
    "            category_column.append(\"\")  \n",
    "            \n",
    "\n",
    "#delete the first element in each array element because it containes the name of the column           \n",
    "phone_column.pop(0) \n",
    "category_column.pop(0) \n",
    "address_column.pop(0) \n",
    "company_name_column.pop(0) \n",
    "\n",
    "#test code\n",
    "#print(category_column)\n",
    "print(len(category_column))\n",
    "#print(phone_column)\n",
    "print(len(phone_column))\n",
    "#print(phone_column)\n",
    "print(len(company_name_column))\n",
    "#print(company_name_column)\n",
    "print(len(address_column))\n",
    "#print(address_column)\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Category': category_column,\n",
    "    'Address': address_column,\n",
    "    'Phone': phone_column,\n",
    "    'Company Name': company_name_column\n",
    "}\n",
    "\n",
    "df_website = pd.DataFrame(data)\n",
    "#print(df_website)\n",
    "\n",
    "output_file = 'output_data_website.csv'  \n",
    "df_website.to_csv(output_file, index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
