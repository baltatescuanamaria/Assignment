{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, I parsed through all three of the cvs files. I did it going line by line, at the end having a dataframe for each data set. I chose this way of transforming because it prevents future errors occuring from the initial data.\n",
    "\n",
    "While going through the data, I've tried to change the format of the most important fields, so that is constant thoughout the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_column = []\n",
    "address_column = []\n",
    "category_column = []\n",
    "city_column = []\n",
    "country_code_column = []\n",
    "country_name_column = []\n",
    "description_column = []\n",
    "email_column = []\n",
    "link_column = []\n",
    "company_name_column = []\n",
    "page_type_column = []\n",
    "phone_column = []\n",
    "phone_country_code_column = []\n",
    "region_code_column = []\n",
    "region_name_column = []\n",
    "zip_code_column = []\n",
    "\n",
    "with open('facebook_dataset.csv', mode='r', encoding='utf-8') as file:\n",
    "    file = csv.reader(file, delimiter=',', quotechar='\"')\n",
    "    for row in file:\n",
    "        if len(row) > 15:\n",
    "            domain_column.append(row[0])\n",
    "            address_column.append(row[1])\n",
    "            category_column.append(row[2].replace('|', ', '))\n",
    "            city_column.append(row[3].title())\n",
    "            country_code_column.append(row[4].title())\n",
    "            country_name_column.append(row[5].title())\n",
    "            description_column.append(row[6])\n",
    "            email_column.append(row[7])\n",
    "            link_column.append(row[8])\n",
    "            company_name_column.append(row[9].title())\n",
    "            page_type_column.append(row[10])\n",
    "            phone_column.append(row[11])\n",
    "            phone_country_code_column.append(row[12])\n",
    "            region_code_column.append(row[13].title())\n",
    "            region_name_column.append(row[14])\n",
    "            zip_code_column.append(row[15])\n",
    "        else:\n",
    "            domain_column.append(\"\")\n",
    "            address_column.append(\"\")\n",
    "            category_column.append(\"\")\n",
    "            city_column.append(\"\")\n",
    "            country_code_column.append(\"\")\n",
    "            country_name_column.append(\"\")\n",
    "            description_column.append(\"\")\n",
    "            email_column.append(\"\")\n",
    "            link_column.append(\"\")\n",
    "            company_name_column.append(\"\")\n",
    "            page_type_column.append(\"\")\n",
    "            phone_column.append(\"\")\n",
    "            phone_country_code_column.append(\"\")\n",
    "            region_code_column.append(\"\")\n",
    "            region_name_column.append(\"\")\n",
    "            zip_code_column.append(\"\")\n",
    "\n",
    "\n",
    "\n",
    "#delete the first element in each array element because it containes the name of the column           \n",
    "domain_column.pop(0)\n",
    "address_column.pop(0)\n",
    "category_column.pop(0)\n",
    "city_column.pop(0)\n",
    "country_code_column.pop(0)\n",
    "country_name_column.pop(0)\n",
    "description_column.pop(0)\n",
    "email_column.pop(0)\n",
    "link_column.pop(0)\n",
    "company_name_column.pop(0)\n",
    "page_type_column.pop(0)\n",
    "phone_column.pop(0)\n",
    "phone_country_code_column.pop(0)\n",
    "region_code_column.pop(0)\n",
    "region_name_column.pop(0)\n",
    "zip_code_column.pop(0)\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Domain': domain_column,\n",
    "    'Address': address_column,\n",
    "    'Categories': category_column,\n",
    "    'City Name': city_column,\n",
    "    'Country Code': country_code_column,\n",
    "    'Country Name': country_name_column,\n",
    "    'Description': description_column,\n",
    "    'Email': email_column,\n",
    "    'Link': link_column,\n",
    "    'Company Name': company_name_column,\n",
    "    'Page Type': page_type_column,\n",
    "    'Phone': phone_column,\n",
    "    'Phone Country Code': phone_country_code_column,\n",
    "    'Region Code': region_code_column,\n",
    "    'Region Name': region_name_column,\n",
    "    'Zip Code': zip_code_column  \n",
    "}\n",
    "\n",
    "df_facebook = pd.DataFrame(data)\n",
    "df_facebook = df_facebook.drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "#output in a file for easier reading\n",
    "output_file = 'output_data_facebook.txt'  \n",
    "df_facebook.to_csv(output_file, index=False, sep = ' ', quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_column = []\n",
    "address_column = []\n",
    "category_column = []\n",
    "city_column = []\n",
    "country_code_column = []\n",
    "country_name_column = []\n",
    "text_column = []\n",
    "raw_address_column = []\n",
    "raw_phone_number_column = []\n",
    "company_name_column = []\n",
    "phone_column = []\n",
    "phone_country_code_column = []\n",
    "region_code_column = []\n",
    "region_name_column = []\n",
    "zip_code_column = []\n",
    "\n",
    "with open('google_dataset.csv', mode='r', encoding='utf-8') as file:\n",
    "    file = csv.reader(file, delimiter=',', quotechar='\"')\n",
    "    for row in file:\n",
    "        if len(row) > 14:\n",
    "            address_column.append(row[0])\n",
    "            category_column.append(row[1])\n",
    "            city_column.append(row[2].title())\n",
    "            country_code_column.append(row[3].title())\n",
    "            country_name_column.append(row[4].title())\n",
    "            company_name_column.append(row[5].title())\n",
    "            phone_column.append(row[6])\n",
    "            phone_country_code_column.append(row[7])\n",
    "            raw_address_column.append(row[8])\n",
    "            raw_phone_number_column.append(row[9])\n",
    "            region_code_column.append(row[10])\n",
    "            region_name_column.append(row[11].title())\n",
    "            text_column.append(row[12])\n",
    "            zip_code_column.append(row[13])\n",
    "            domain_column.append(row[14])\n",
    "        else:\n",
    "            address_column.append(\"\")\n",
    "            category_column.append(\"\")\n",
    "            city_column.append(\"\")\n",
    "            country_code_column.append(\"\")\n",
    "            country_name_column.append(\"\")\n",
    "            company_name_column.append(\"\")\n",
    "            phone_column.append(\"\")\n",
    "            phone_country_code_column.append(\"\")\n",
    "            raw_address_column.append(\"\")\n",
    "            raw_phone_number_column.append(\"\")\n",
    "            region_code_column.append(\"\")\n",
    "            region_name_column.append(\"\")\n",
    "            text_column.append(\"\")\n",
    "            zip_code_column.append(\"\")\n",
    "            domain_column.append(\"\")\n",
    "\n",
    "\n",
    "\n",
    "#delete the first element in each array element because it containes the name of the column           \n",
    "address_column.pop(0)\n",
    "category_column.pop(0)\n",
    "city_column.pop(0)\n",
    "country_code_column.pop(0)\n",
    "country_name_column.pop(0)\n",
    "company_name_column.pop(0)\n",
    "phone_column.pop(0)\n",
    "phone_country_code_column.pop(0)\n",
    "raw_address_column.pop(0)\n",
    "raw_phone_number_column.pop(0)\n",
    "region_code_column.pop(0)\n",
    "region_name_column.pop(0)\n",
    "text_column.pop(0)\n",
    "zip_code_column.pop(0)\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Address': address_column,\n",
    "    'Categories': category_column,\n",
    "    'City Name': city_column,\n",
    "    'Country Code': country_code_column,\n",
    "    'Country Name': country_name_column,\n",
    "    'Company Name': company_name_column,\n",
    "    'Phone': phone_column,\n",
    "    'Phone Country Code': phone_country_code_column,\n",
    "    'Raw Address': raw_address_column,\n",
    "    'Raw Phone': raw_phone_number_column,\n",
    "    'Region Code': region_code_column,\n",
    "    'Region Name': region_name_column,\n",
    "    'Text': text_column,\n",
    "    'Zip Code': zip_code_column\n",
    "}\n",
    "\n",
    "df_google = pd.DataFrame(data)\n",
    "df_google = df_google.drop_duplicates()\n",
    "\n",
    "#output in a file for easier reading\n",
    "output_file = 'output_data_google.txt'  \n",
    "df_google.to_csv(output_file, index=False, sep = ' ', quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_domain_column = []\n",
    "domain_suffix_column = []\n",
    "language_column  = []\n",
    "legal_name_column = []\n",
    "city_column = []\n",
    "country_name_column = []\n",
    "region_column = []\n",
    "phone_column = []\n",
    "site_name_column = []\n",
    "tld_column = []\n",
    "category_column = []\n",
    "\n",
    "with open('website_dataset.csv', mode='r', encoding='utf-8') as file:\n",
    "    file = csv.reader(file, delimiter=';', quotechar='\"')\n",
    "    for row in file:\n",
    "        if len(row) > 10:\n",
    "            root_domain_column.append(row[0])\n",
    "            domain_suffix_column.append(row[1])\n",
    "            language_column.append(row[2])\n",
    "            legal_name_column.append(row[3])\n",
    "            city_column.append(row[4].title())\n",
    "            country_name_column.append(row[5].title())\n",
    "            region_column.append(row[6].title())\n",
    "            phone_column.append(\"+\" + row[7])\n",
    "            site_name_column.append(row[8])\n",
    "            tld_column.append(row[9])\n",
    "            category_column.append(row[10].title())\n",
    "        else:\n",
    "            root_domain_column .append(\"\")\n",
    "            domain_suffix_column.append(\"\")\n",
    "            language_column.append(\"\")\n",
    "            legal_name_column.append(\"\")\n",
    "            city_column.append(\"\")\n",
    "            country_name_column.append(\"\")\n",
    "            region_column.append(\"\")\n",
    "            phone_column.append(\"\")\n",
    "            site_name_column.append(\"\")\n",
    "            tld_column.append(\"\")\n",
    "            category_column.append(\"\")\n",
    "\n",
    "\n",
    "\n",
    "#delete the first element in each array element because it containes the name of the column             root_domain_column .append(\"\")\n",
    "root_domain_column.pop(0)\n",
    "domain_suffix_column.pop(0)\n",
    "language_column.pop(0)\n",
    "legal_name_column.pop(0)\n",
    "city_column.pop(0)\n",
    "country_name_column.pop(0)\n",
    "region_column.pop(0)\n",
    "phone_column.pop(0)\n",
    "site_name_column.pop(0)\n",
    "tld_column.pop(0)\n",
    "category_column.pop(0)        \n",
    "\n",
    "data = {\n",
    "    'Root Domain': root_domain_column,\n",
    "    'Domain Suffix': domain_suffix_column,\n",
    "    'Language': language_column,\n",
    "    'Company Name': legal_name_column,\n",
    "    'City Name': city_column,\n",
    "    'Country Name': country_name_column,\n",
    "    'Region Name': region_column,\n",
    "    'Phone': phone_column,\n",
    "    'Site Name': site_name_column,\n",
    "    'TLD': tld_column,\n",
    "    'Categories': category_column\n",
    "}\n",
    "\n",
    "df_website = pd.DataFrame(data)\n",
    "df_website = df_website.drop_duplicates()\n",
    "\n",
    "df_website['Link'] = 'https://' + df_website['Root Domain'] + '.' + df_website['Domain Suffix'] + '/' + df_website['TLD']\n",
    "\n",
    "#output in a file for easier reading\n",
    "output_file = 'output_data_website.txt'  \n",
    "df_website.to_csv(output_file, sep=' ', index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I merged the DataFrame for Google with the one for Facebook. The keys I chose for this join are 'Company Name', 'Country Name', 'City Name', and 'Zip Code'. After examining the data, I concluded that these columns form a fairly good set. The reasoning behind this choice is that there cannot be two companies with the same name in the same country and city. Even if there were, the zip code provides an extra layer of uniqueness.\n",
    "\n",
    "The other columns were a bit too difficult to work with for joining mainly because they contained slightly different versions of the text, yet conveyed the same message. \n",
    "\n",
    "As for the remaining data, I prioritized the information provided by Google. The main reason is that I thought Google has several methods for updating information, making it more reliable than a Facebook page.\n",
    "\n",
    "After that, I merged the new DataFrame with the Website DataFrame. While parsing the data in the Website dataset, I've created a new column where I formed the link for each row, using the other columns that provided information about the link. This column is now also used to join the two DataFrames.\n",
    "\n",
    "At the end, I've chosen to delete all the rows that do not contain the country name or the city name. If after all the joinings there aren't any matches, maybe it is not good data. I had an idea to use the country and region codes and match the rows with no data with the ones that have the same codes, but I could not come with a good solution. In the final DataFrame there are rows in which the Zip Code is missing. My thought process was that this field is important, but not crucial for the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chose the columns that are important\n",
    "selected_columns_facebook = ['Company Name', 'Country Name', 'City Name', 'Region Name', 'Address', 'Categories', 'Phone', 'Zip Code', 'Link']\n",
    "selected_columns_google = ['Company Name', 'Country Name', 'City Name', 'Region Name', 'Address', 'Categories', 'Phone', 'Zip Code']\n",
    "\n",
    "new_df_facebook = df_facebook[selected_columns_facebook]\n",
    "new_df_google = df_google[selected_columns_google]\n",
    "\n",
    "#joined the two dataframes\n",
    "merged_df = pd.merge(new_df_google, new_df_facebook, on=['Company Name', 'Country Name', 'City Name', 'Zip Code'], how='outer', suffixes=('_facebook', '_google'))\n",
    "\n",
    "\n",
    "#for the Nan values\n",
    "merged_df['Address'] = merged_df['Address_facebook'].combine_first(merged_df['Address_google'])\n",
    "merged_df['Categories'] = merged_df['Categories_facebook'].combine_first(merged_df['Categories_google'])\n",
    "merged_df['Phone'] = merged_df['Phone_facebook'].combine_first(merged_df['Phone_google'])\n",
    "merged_df['Region Name'] = merged_df['Region Name_facebook'].combine_first(merged_df['Region Name_google'])\n",
    "\n",
    "#delete the columns that were used previously \n",
    "merged_df.drop(columns=['Address_facebook', 'Address_google', 'Categories_facebook', 'Categories_google', \n",
    "                        'Phone_facebook', 'Phone_google', 'Region Name_facebook', 'Region Name_google'], inplace=True)\n",
    "\n",
    "\n",
    "merged_df.drop_duplicates(['Company Name', 'Country Name', 'City Name', 'Zip Code'], inplace=True)\n",
    "merged_df = merged_df[selected_columns_facebook]\n",
    "\n",
    "\n",
    "selected_columns_website = ['Company Name', 'City Name', 'Country Name', 'Region Name', 'Phone', 'Link']\n",
    "new_df_website = df_website[selected_columns_website]\n",
    "\n",
    "final_df = pd.merge(merged_df, new_df_website, on = ['Country Name', 'Company Name', 'City Name', 'Region Name', 'Phone', 'Link'], how = 'outer', suffixes=('_merged', '_website'))\n",
    "\n",
    "final_df.drop_duplicates(['Country Name', 'City Name', 'Region Name', 'Phone', 'Link'])\n",
    "final_df = final_df[selected_columns_google]\n",
    "\n",
    "final_df.replace(\"\", np.nan, inplace=True)\n",
    "cleaned_df = final_df.dropna(subset=['Company Name', 'Country Name'])\n",
    "\n",
    "output_file = 'output_data.txt'\n",
    "cleaned_df.to_csv(output_file, sep=' ', index=False, quoting=csv.QUOTE_NONNUMERIC)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
